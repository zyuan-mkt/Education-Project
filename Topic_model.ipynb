{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic model.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbEcr_m4K2M5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcgsQuYALbBo",
        "outputId": "a1d6d112-9a43-4c64-c557-854a0a1d8b23"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47H_xJmuLRm7",
        "outputId": "3e83a7d5-a54f-460b-b939-469f51df44fa"
      },
      "source": [
        "donor = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/education project/data/clean_essay.csv\")\n",
        "essay_lda = donor[['resource_type','primary_focus_area', 'poverty_level','text']]\n",
        "essay_lda['doc'] = essay_lda['text'].apply(lambda x: x.split(\" \"))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcOOo_hXO1N2",
        "outputId": "80649ad5-ade4-4878-e50e-53beb0c51d73"
      },
      "source": [
        "essay_lda.loc[(essay_lda['poverty_level'] == 'highest poverty'), \"poor\"] = 1\n",
        "essay_lda.poor.fillna(0,inplace=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[key] = _infer_fill_value(value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  downcast=downcast,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H20cBuBSP1wI"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "essay_train, essay_test = train_test_split(essay_lda, test_size=0.3, random_state=1234)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5v17izFL_qs"
      },
      "source": [
        "from gensim import corpora, models, similarities\n",
        "dictionary = corpora.Dictionary(essay_train.doc)\n",
        "corpus = [dictionary.doc2bow(text) for text in essay_train.doc]\n",
        "# print(dictionary)\n",
        "# print([[(dictionary[id],freq) for id, freq in cp] for cp in corpus[:1]])\n",
        "tfidf = models.TfidfModel(corpus)\n",
        "transformed_tfidf = tfidf[corpus]\n",
        "\n",
        "import gensim\n",
        "import logging # This allows for seeing if the model converges. A log file is created.\n",
        "logging.basicConfig(filename='lda_model.log', format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "lda_train = gensim.models.ldamulticore.LdaMulticore(\n",
        "                       corpus=transformed_tfidf,\n",
        "                       num_topics=10,\n",
        "                       id2word=dictionary,\n",
        "                       per_word_topics=True)\n",
        "lda_train.save('lda_train.model')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjAucUBJMRA4",
        "outputId": "b5dea980-44c0-47a3-8577-77cabe714e25"
      },
      "source": [
        "lda_train.print_topics(num_words=15)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.002*\"book\" + 0.002*\"technology\" + 0.002*\"math\" + 0.002*\"ipod\" + 0.002*\"computer\" + 0.002*\"read\" + 0.002*\"calculator\" + 0.001*\"science\" + 0.001*\"reading\" + 0.001*\"skill\" + 0.001*\"listen\" + 0.001*\"library\" + 0.001*\"center\" + 0.001*\"level\" + 0.001*\"child\"'),\n",
              " (1,\n",
              "  '0.002*\"book\" + 0.002*\"read\" + 0.001*\"technology\" + 0.001*\"science\" + 0.001*\"ipad\" + 0.001*\"computer\" + 0.001*\"reading\" + 0.001*\"math\" + 0.001*\"child\" + 0.001*\"game\" + 0.001*\"center\" + 0.001*\"kid\" + 0.001*\"use\" + 0.001*\"skill\" + 0.001*\"listen\"'),\n",
              " (2,\n",
              "  '0.003*\"book\" + 0.002*\"read\" + 0.002*\"reading\" + 0.001*\"listen\" + 0.001*\"music\" + 0.001*\"story\" + 0.001*\"center\" + 0.001*\"technology\" + 0.001*\"write\" + 0.001*\"child\" + 0.001*\"cd\" + 0.001*\"math\" + 0.001*\"word\" + 0.001*\"art\" + 0.001*\"kid\"'),\n",
              " (3,\n",
              "  '0.004*\"book\" + 0.003*\"read\" + 0.002*\"reading\" + 0.002*\"computer\" + 0.002*\"child\" + 0.002*\"science\" + 0.002*\"technology\" + 0.002*\"camera\" + 0.002*\"math\" + 0.002*\"classroom\" + 0.002*\"material\" + 0.002*\"library\" + 0.002*\"art\" + 0.002*\"reader\" + 0.002*\"kid\"'),\n",
              " (4,\n",
              "  '0.003*\"book\" + 0.002*\"read\" + 0.002*\"math\" + 0.002*\"science\" + 0.002*\"center\" + 0.002*\"reading\" + 0.002*\"computer\" + 0.002*\"technology\" + 0.001*\"skill\" + 0.001*\"ipad\" + 0.001*\"library\" + 0.001*\"game\" + 0.001*\"story\" + 0.001*\"classroom\" + 0.001*\"child\"'),\n",
              " (5,\n",
              "  '0.003*\"music\" + 0.003*\"listen\" + 0.002*\"book\" + 0.002*\"read\" + 0.002*\"center\" + 0.002*\"instrument\" + 0.001*\"cd\" + 0.001*\"language\" + 0.001*\"math\" + 0.001*\"play\" + 0.001*\"technology\" + 0.001*\"reading\" + 0.001*\"english\" + 0.001*\"reader\" + 0.001*\"hear\"'),\n",
              " (6,\n",
              "  '0.003*\"ipad\" + 0.003*\"technology\" + 0.002*\"music\" + 0.002*\"book\" + 0.002*\"math\" + 0.002*\"game\" + 0.002*\"read\" + 0.002*\"science\" + 0.002*\"camera\" + 0.002*\"center\" + 0.002*\"child\" + 0.002*\"world\" + 0.002*\"skill\" + 0.002*\"board\" + 0.002*\"use\"'),\n",
              " (7,\n",
              "  '0.003*\"science\" + 0.003*\"book\" + 0.002*\"ipad\" + 0.002*\"computer\" + 0.002*\"technology\" + 0.002*\"read\" + 0.002*\"math\" + 0.002*\"supply\" + 0.002*\"pencil\" + 0.002*\"child\" + 0.002*\"material\" + 0.001*\"world\" + 0.001*\"reading\" + 0.001*\"write\" + 0.001*\"level\"'),\n",
              " (8,\n",
              "  '0.003*\"book\" + 0.002*\"read\" + 0.001*\"technology\" + 0.001*\"camera\" + 0.001*\"computer\" + 0.001*\"reading\" + 0.001*\"nook\" + 0.001*\"child\" + 0.001*\"math\" + 0.001*\"projector\" + 0.001*\"reader\" + 0.001*\"supply\" + 0.001*\"level\" + 0.001*\"college\" + 0.001*\"library\"'),\n",
              " (9,\n",
              "  '0.003*\"art\" + 0.002*\"paper\" + 0.002*\"book\" + 0.002*\"supply\" + 0.002*\"camera\" + 0.001*\"read\" + 0.001*\"material\" + 0.001*\"writing\" + 0.001*\"document\" + 0.001*\"math\" + 0.001*\"child\" + 0.001*\"technology\" + 0.001*\"write\" + 0.001*\"create\" + 0.001*\"project\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3mlcmaVNDge"
      },
      "source": [
        "train_vecs = []\n",
        "for i in range(essay_train.shape[0]):\n",
        "    top_topics = (\n",
        "        lda_train.get_document_topics(transformed_tfidf[i],\n",
        "                                      minimum_probability=0.0)\n",
        "    )\n",
        "    topic_vec = [top_topics[i][1] for i in range(10)]\n",
        "    topic_vec.extend([len(essay_train.iloc[i].text)])\n",
        "    train_vecs.append(topic_vec)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRHiixoSNkmC",
        "outputId": "805444cf-5e73-44b6-9810-7f7d71fbc2bf"
      },
      "source": [
        "X = np.array(train_vecs)\n",
        "y = np.array(essay_train.poor)\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score \n",
        "kf = KFold(5, shuffle=True, random_state=1234)\n",
        "cv_lr_f1, cv_lrsgd_f1, cv_svcsgd_f1,  = [], [], []\n",
        "\n",
        "for train_ind, val_ind in kf.split(X, y):\n",
        "    # Assign CV IDX\n",
        "    X_train, y_train = X[train_ind], y[train_ind]\n",
        "    X_val, y_val = X[val_ind], y[val_ind]\n",
        "    \n",
        "    # Scale Data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scale = scaler.fit_transform(X_train)\n",
        "    X_val_scale = scaler.transform(X_val)\n",
        "\n",
        "    # Logisitic Regression\n",
        "    lr = LogisticRegression(\n",
        "        class_weight= 'balanced',\n",
        "        solver='newton-cg',\n",
        "        fit_intercept=True\n",
        "    ).fit(X_train_scale, y_train)\n",
        "\n",
        "    y_pred = lr.predict(X_val_scale)\n",
        "    cv_lr_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
        "    \n",
        "    # Logistic Regression SGD\n",
        "    sgd = SGDClassifier(\n",
        "        max_iter=1000,\n",
        "        tol=1e-3,\n",
        "        loss='log',\n",
        "        class_weight='balanced'\n",
        "    ).fit(X_train_scale, y_train)\n",
        "    \n",
        "    y_pred = sgd.predict(X_val_scale)\n",
        "    cv_lrsgd_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
        "    \n",
        "    # SGD Modified Huber\n",
        "    sgd_huber = SGDClassifier(\n",
        "        max_iter=1000,\n",
        "        tol=1e-3,\n",
        "        alpha=20,\n",
        "        loss='modified_huber',\n",
        "        class_weight='balanced'\n",
        "    ).fit(X_train_scale, y_train)\n",
        "    \n",
        "    y_pred = sgd_huber.predict(X_val_scale)\n",
        "    cv_svcsgd_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
        "\n",
        "print(f'Logistic Regression Val f1: {np.mean(cv_lr_f1):.3f} +- {np.std(cv_lr_f1):.3f}')\n",
        "print(f'Logisitic Regression SGD Val f1: {np.mean(cv_lrsgd_f1):.3f} +- {np.std(cv_lrsgd_f1):.3f}')\n",
        "print(f'SVM Huber Val f1: {np.mean(cv_svcsgd_f1):.3f} +- {np.std(cv_svcsgd_f1):.3f}')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Val f1: 0.598 +- 0.048\n",
            "Logisitic Regression SGD Val f1: 0.633 +- 0.081\n",
            "SVM Huber Val f1: 0.323 +- 0.395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXxS1YKCUzKW"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io_f8W2UUaB-"
      },
      "source": [
        "test_vecs = []\n",
        "for i in range(essay_test.shape[0]):\n",
        "    top_topics = (\n",
        "        lda_train.get_document_topics(transformed_tfidf[i],\n",
        "                                      minimum_probability=0.0)\n",
        "    )\n",
        "    topic_vec = [top_topics[i][1] for i in range(10)]\n",
        "    topic_vec.extend([len(essay_test.iloc[i].text)])\n",
        "    test_vecs.append(topic_vec)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h75MGhrLUeNV",
        "outputId": "e18759b3-6f7e-4d08-a128-81ab7d4329d9"
      },
      "source": [
        "X = np.array(test_vecs)\n",
        "y = np.array(essay_test.poor)\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score \n",
        "kf = KFold(5, shuffle=True, random_state=1234)\n",
        "cv_lr_f1, cv_lrsgd_f1, cv_svcsgd_f1,  = [], [], []\n",
        "\n",
        "for train_ind, val_ind in kf.split(X, y):\n",
        "    # Assign CV IDX\n",
        "    X_train, y_train = X[train_ind], y[train_ind]\n",
        "    X_val, y_val = X[val_ind], y[val_ind]\n",
        "    \n",
        "    # Scale Data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scale = scaler.fit_transform(X_train)\n",
        "    X_val_scale = scaler.transform(X_val)\n",
        "\n",
        "    # Logisitic Regression\n",
        "    lr = LogisticRegression(\n",
        "        class_weight= 'balanced',\n",
        "        solver='newton-cg',\n",
        "        fit_intercept=True\n",
        "    ).fit(X_train_scale, y_train)\n",
        "\n",
        "    y_pred = lr.predict(X_val_scale)\n",
        "    cv_lr_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
        "    \n",
        "    # Logistic Regression SGD\n",
        "    sgd = SGDClassifier(\n",
        "        max_iter=1000,\n",
        "        tol=1e-3,\n",
        "        loss='log',\n",
        "        class_weight='balanced'\n",
        "    ).fit(X_train_scale, y_train)\n",
        "    \n",
        "    y_pred = sgd.predict(X_val_scale)\n",
        "    cv_lrsgd_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
        "    \n",
        "    # SGD Modified Huber\n",
        "    sgd_huber = SGDClassifier(\n",
        "        max_iter=1000,\n",
        "        tol=1e-3,\n",
        "        alpha=20,\n",
        "        loss='modified_huber',\n",
        "        class_weight='balanced'\n",
        "    ).fit(X_train_scale, y_train)\n",
        "    \n",
        "    y_pred = sgd_huber.predict(X_val_scale)\n",
        "    cv_svcsgd_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
        "\n",
        "print(f'Logistic Regression Val f1: {np.mean(cv_lr_f1):.3f} +- {np.std(cv_lr_f1):.3f}')\n",
        "print(f'Logisitic Regression SGD Val f1: {np.mean(cv_lrsgd_f1):.3f} +- {np.std(cv_lrsgd_f1):.3f}')\n",
        "print(f'SVM Huber Val f1: {np.mean(cv_svcsgd_f1):.3f} +- {np.std(cv_svcsgd_f1):.3f}')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Val f1: 0.573 +- 0.049\n",
            "Logisitic Regression SGD Val f1: 0.640 +- 0.088\n",
            "SVM Huber Val f1: 0.489 +- 0.399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKWo_SD3Urpf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}